calc_rmse(Credit_test$Rating, preds)
#15.08
library(ISLR2)
Credit_D = ISLR2::Credit
library(ISLR2)
Credit_D = ISLR2::Credit
set.seed(43206)
Credit_test_idx =sample(nrow(Credit_D),80)
Credit_test = Credit_D[Credit_test_idx,] #test
Other_Data = Credit_D[-Credit_test_idx,] #train
Credit_Val_dix = sample(nrow(Other_Data),64)
Credit_val = Other_Data[Credit_Val_dix,] #val
Credit_est= Other_Data[-Credit_Val_dix,] #est
Ks_2 = seq(1:100)
calc_rmse = function(actual, predicted) {
sqrt(mean((actual - predicted) ^ 2))
}
rmses<-c()
for  (i in Ks_2){
mode1 = knnreg(Rating~scale(Income)+scale(Limit)+scale(Balance), data = Credit_est, k = i, use.all = TRUE)
preds =predict(mode1, Credit_val)
rmse_1=calc_rmse(Credit_val$Rating, preds)
rmses<-c(rmses,rmse_1)
}
df_summary_2<-data.frame("Ks" =Ks_2,
"RMSE"=rmses)
df_summary_2 %>%
ggplot(aes(x = Ks, y = RMSE))+
geom_line(size = 1)
which.min(rmses)
mode2 = knnreg(Rating~scale(Income)+scale(Limit)+scale(Balance), data = Other_Data, k = , use.all = TRUE)
preds =predict(mode2, Credit_test)
calc_rmse(Credit_test$Rating, preds)
Ks[which.min(rmses)]
mode2 = knnreg(Rating~scale(Income)+scale(Limit)+scale(Balance), data = Other_Data, k =13 , use.all = TRUE)
preds =predict(mode2, Credit_test)
calc_rmse(Credit_test$Rating, preds)
Ks_2[which.min(rmses)]
mode2 = knnreg(Rating~scale(Income)+scale(Limit)+scale(Balance), data = Other_Data, k =7 , use.all = TRUE)
preds =predict(mode2, Credit_test)
calc_rmse(Credit_test$Rating, preds)
library(ISLR2)
Credit_D = ISLR2::Credit
set.seed(43206)
Credit_test_idx =sample(nrow(Credit_D),80)
Credit_test = Credit_D[Credit_test_idx,] #test
Other_Data = Credit_D[-Credit_test_idx,] #train
Credit_Val_dix = sample(nrow(Other_Data),64)
Credit_val = Other_Data[Credit_Val_dix,] #val
Credit_est= Other_Data[-Credit_Val_dix,] #est
Ks_2 = seq(1:100)
calc_rmse = function(actual, predicted) {
sqrt(mean((actual - predicted) ^ 2))
}
rmses<-c()
for  (i in Ks_2){
mode1 = knnreg(Rating~scale(Income)+scale(Limit)+scale(Balance), data = Credit_est, k = i)
preds =predict(mode1, Credit_val)
rmse_1=calc_rmse(Credit_val$Rating, preds)
rmses<-c(rmses,rmse_1)
}
df_summary_2<-data.frame("Ks" =Ks_2,
"RMSE"=rmses)
df_summary_2 %>%
ggplot(aes(x = Ks, y = RMSE))+
geom_line(size = 1)
Ks_2[which.min(rmses)]
Ks_2[which.min(rmses)]
mode2 = knnreg(Rating~scale(Income)+scale(Limit)+scale(Balance), data = Other_Data, k =7 )
preds =predict(mode2, Credit_test)
calc_rmse(Credit_test$Rating, preds)
#15.08
seq(1:100)
knitr::opts_chunk$set(echo = TRUE)
library(tibble)     # data frame printing
library(dplyr)      # data manipulation
library(knitr)      # creating tables
library(kableExtra)
library(ISLR2)
library(boot)
set.seed(43208)
trn.boston.idx=sample(nrow(Boston),450)
boston.trn=Boston[trn.boston.idx,] # training data
boston.tst=Boston[-trn.boston.idx,] # test data
set.seed(43208)
#Leave on out cross validation:
glm.fit <- glm(crim ~ medv+lstat+rm, data = boston.trn)
coef(glm.fit)
###
lm.fit <- lm(crim ~ medv+lstat+rm, data = boston.trn)
coef(lm.fit)
###
glm.fit <- glm(crim ~ medv+lstat+rm, data = boston.trn)
cv.err <- cv.glm(boston.trn, glm.fit)
cv.err$delta[1]
set.seed(43208)
#5 fold cv
glm.fit <- glm(crim ~ medv+lstat+rm, data = boston.trn)
cv.glm(boston.trn, glm.fit, K = 5)$delta[1]
set.seed(43208)
#10 fold cv
glm.fit <- glm(crim ~ medv+lstat+rm, data = boston.trn)
cv.glm(boston.trn, glm.fit, K = 10)$delta[1]
library(tree)
Boston_org<-Boston
#control=tree.control(nobs=nrow(boston.trn),mindev=0)
set.seed(43208)
tree.boston <- tree(formula = crim~., data = boston.trn, control=tree.control(nobs=nrow(boston.trn),mindev=0))
###
set.seed(43208)
cv.boston <- cv.tree(tree.boston)
plot(cv.boston$size, cv.boston$dev, type = "b")
###
prune.boston <- prune.tree(tree.boston, best = 7)
plot(prune.boston)
text(prune.boston, pretty = 0)
yhat <- predict(prune.boston, newdata = boston.tst)
#boston.test <- Boston[-train, "medv"]
#plot(yhat, boston.test)
#abline(0, 1)
sqrt(mean((yhat - boston.tst$crim)^2))
x=c(42, 45, 38, 35, 49, 28, 44, 40, 45, 42)
y=c(126, 145, 112, 107, 144,  83, 129, 119, 131, 127)
data=tibble(x,y)
data %>%
kable() %>%
kable_styling(full_width = FALSE)
alpha.fn <- function(data, index) {
X <- data$x[index]
Y <- data$y[index]
#(var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
return(c(mean(X), mean(Y), cov(X,Y)))
}
###
alpha.fn(data, 1:10)
###
alpha.fn(data, sample(10, 10, replace = T))
###
res_boot<-boot(data, alpha.fn, R = 1000)
mean(res_boot$t[,1])
mean(res_boot$t[,2])
mean(res_boot$t[,3])
res_boot
boot.fn <- function(data, index){
coef(lm(y ~ x, data = data, subset = index))
}
boot.fn(data, 1:10)
boot(data, boot.fn, 1000)
tinytex::install_tinytex()
tinytex::uninstall_tinytex()
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
attach(ISLR2::Boston)
fit.1 <- lm(nox ~ dis, data = Boston)
attach(ISLR2::Boston)
fit.1 <- lm(nox ~ dis, data = Boston)
library(ISLR2)
attach(ISLR2::Boston)
fit.1 <- lm(nox ~ dis, data = Boston)
fit.2 <- lm(nox ~ poly(dis, 2), data = Boston)
fit.2 <- lm(nox ~ poly(dis, 2), data = Boston)
fit.1 <- lm(nox ~ dis, data = Boston)
fit.2 <- lm(nox ~ poly(dis, 2), data = Boston)
fit.3 <- lm(nox ~ poly(dis, 3), data = Boston)
fit.4 <- lm(nox ~ poly(dis, 4), data = Boston)
fit.5 <- lm(nox ~ poly(dis, 5), data = Boston)
fit.6 <- lm(nox ~ poly(dis, 6), data = Boston)
fit.7 <- lm(nox ~ poly(dis, 7), data = Boston)
fit.8 <- lm(nox ~ poly(dis, 8), data = Boston)
fit.9 <- lm(nox ~ poly(dis, 9), data = Boston)
fit.10 <- lm(nox ~ poly(dis, 10), data = Boston)
par(mfrow = c(1, 2), mar = c(4.5, 4.5, 1, 1),
oma = c(0, 0, 4, 0))
plot(nox, dis, xlim = agelims, cex = .5, col = "darkgrey")
plot(nox, dis, cex = .5, col = "darkgrey")
par(mfrow = c(1, 2), mar = c(4.5, 4.5, 1, 1),
oma = c(0, 0, 4, 0))
plot(nox, dis, cex = .5, col = "darkgrey")
plot(fit.1)
plot(fit.1$fitted.values)
anova(fit.1, fit.2, fit.3, fit.4, fit.5,fit.6, fit.7, fit.8, fit.9, fit.10)
anova(fit.1, fit.2, fit.3, fit.4, fit.5,fit.6, fit.7, fit.8, fit.9, fit.10)
library(MASS)
k <- 10
fold <- sample(k, nrow(Boston), replace = TRUE)
## For each span from 1 to 10 we can calculate the CV test error:
mse <- numeric(k)
span <- seq(1, 10, by = 1)
cv <- numeric(length(span))
for (j in seq_along(span))
{
for (i in seq_len(k))
{
take <- fold == i
foldi <- Boston[take, ]
foldOther <- Boston[!take, ]
f <- loess(dis ~ nox, data=foldOther, span=span[j])
pred <- predict(f, foldi)
mse[i] <- mean((pred - foldi$dis)^2, na.rm = TRUE)
}
cv[j]<- mean(mse)
}
plot(span, cv)
k <- 10
fold <- sample(k, nrow(Boston), replace = TRUE)
## For each span from 1 to 10 we can calculate the CV test error:
mse <- numeric(k)
span <- seq(1, 10, by = 1)
cv <- numeric(length(span))
for (j in seq_along(span))
{
for (i in seq_len(k))
{
take <- fold == i
foldi <- Boston[take, ]
foldOther <- Boston[!take, ]
f <- lm(nox ~ poly(dis,j))
pred <- predict(f, foldi)
mse[i] <- mean((pred - foldi$dis)^2, na.rm = TRUE)
}
cv[j]<- mean(mse)
}
plot(span, cv)
library(splines)
fit <- lm(noxe ~ bs(dis, knots = c(4, 5, 6,7)))
fit <- lm(nox ~ bs(dis, knots = c(4, 5, 6,7)))
fit <- smooth.spline(nox, dis, df = 4)
plot(fit)
plot(fit)
plot(fit.4)
fit.6 <- smooth.spline(nox, dis, df = 6)
fit.7 <- smooth.spline(nox, dis, df = 7)
plot(nox, dis, col = "darkgrey")
plot(nox, dis, col = "darkgrey")
lines(fit.4, col = "red", lwd = 2)
lines(fit.5, col = "blue", lwd = 2)
lines(fit.6, col = "green", lwd = 2)
lines(fit.7, col = "black", lwd = 2)
fit.4 <- smooth.spline(nox, dis, df = 4)
fit.5 <- smooth.spline(nox, dis, df = 5)
fit.6 <- smooth.spline(nox, dis, df = 6)
fit.7 <- smooth.spline(nox, dis, df = 7)
plot(nox, dis, col = "darkgrey")
lines(fit.4, col = "red", lwd = 2)
lines(fit.5, col = "blue", lwd = 2)
lines(fit.6, col = "green", lwd = 2)
lines(fit.7, col = "black", lwd = 2)
plot(nox, dis, col = "darkgrey")
lines(fit.4, col = "red", lwd = 2)
lines(fit.5, col = "blue", lwd = 2)
lines(fit.6, col = "green", lwd = 2)
lines(fit.7, col = "black", lwd = 2)
legend("topright", legend = c("4 DF", "5 DF", "6 DF", "7 DF"),,
col = c("red", "blue","green","black"), lty = 1, lwd = 2, cex = .8)
fit.4 <- lm(nox ~ poly(dis, 4), data = Boston)
fit.5 <- lm(nox ~ poly(dis, 5), data = Boston)
fit.6 <- lm(nox ~ poly(dis, 6), data = Boston)
fit.7 <- lm(nox ~ poly(dis, 7), data = Boston)
plot(nox, dis, col = "darkgrey")
lines(fit.4, col = "red", lwd = 2)
lines(fit.5, col = "blue", lwd = 2)
lines(fit.6, col = "green", lwd = 2)
lines(fit.7, col = "black", lwd = 2)
legend("topright", legend = c("4 DF", "5 DF", "6 DF", "7 DF"),,
col = c("red", "blue","green","black"), lty = 1, lwd = 2, cex = .8)
library(ISLR2)
library(ISLR2)
set.seed(432010)
college_idx = sample(1:nrow(College), 600)
college_trn = College[college_idx,] # training data
college_tst = College[-college_idx,] # test data
library(ISLR2)
set.seed(432010)
college_idx = sample(1:nrow(College), 600)
college_trn = College[college_idx,] # training data
college_tst = College[-college_idx,] # test data
gam1 <- lm(Outstate ~ ns(Private, 4) + ns(PhD, 5) + Grad.Rate + Expend,
data = College)
gam1 <- lm(Outstate ~ ns(Private, 4) + ns(PhD, 5) + Grad.Rate + Expend,data = College)
gam1 <- lm(Outstate ~ ns(Private, 4) + ns(PhD, 4) + Grad.Rate + Expend,data = College)
gam1 <- lm(Outstate ~ ns(Private, 4) + PhD + Grad.Rate + Expend,data = College)
gam1 <- lm(Outstate ~ Private + PhD + Grad.Rate + Expend,data = College)
gam1 <- lm(Outstate ~ Private + PhD + Grad.Rate + s(Expend,4),data = College)
gam1 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,4),data = College)
?ns
?s
gam2 <- lm(Outstate ~ Private + PhD + Grad.Rate + s(Expend,4),data = College)
gam2 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,5),data = College)
gam3 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,6),data = College)
gam4 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,7),data = College)
gam1 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,4),data = college_trn)
gam2 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,5),data = college_trn)
gam3 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,6),data = college_trn)
gam4 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,7),data = college_trn)
preds <- predict(gam1, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam1, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam2, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam4, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam4, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
gam1 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,4),data = college_trn)
gam2 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,5),data = college_trn)
gam3 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,6),data = college_trn)
gam4 <- lm(Outstate ~ Private + PhD + Grad.Rate + ns(Expend,7),data = college_trn)
preds <- predict(gam1, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam2, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam4, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam4, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
?gam
gam1 <- gam(Outstate ~ s(Private, bs='ps', sp=0.6) + s(Private, bs='ps', sp=0.6) + Expend, data = college_trn)
library(gam)
gam1 <- gam(Outstate ~ s(Private, bs='ps', sp=0.6) + s(Private, bs='ps', sp=0.6) + Expend, data = college_trn)
gam1 <- gam(Outstate ~ s(Private, sp=0.6) + s(Private, sp=0.6) + Expend, data = college_trn)
View(college_trn)
gam1 <- gam(Outstate ~ Private + PhD + s(Expend, sp = 0.6), data = college_trn)
gam1 <- gam(Outstate ~ Private + PhD +Grad.Rate +  s(Expend, sp = 0.6) , data = college_trn)
summary(gam1)
plot(gam1)
gam1 <- gam(Outstate ~ Private + PhD +s(Grad.Rate, sp = 0.6) +  s(Expend, sp = 0.6) , data = college_trn)
summary(gam1)
plot(gam1)
gam1 <- gam(Outstate ~ Private + PhD +s(Grad.Rate, sp = 0.6) +  s(Expend, sp = 0.6) , data = college_trn)
summary(gam1)
plot(gam1)
gam2 <- gam(Outstate ~ Private + PhD +Grad.Rate +  s(Expend, sp = 0.6) , data = college_trn)
summary(gam1)
summary(gam2)
plot(gam2)
plot(gam1)
plot(gam2)
gam3 <- gam(Outstate ~ Private + PhD +Grad.Rate +  lo(Expend, sp = 0.6) , data = college_trn)
summary(gam3)
plot(gam24)
plot(gam3)
gam3 <- gam(Outstate ~ Private + PhD +Grad.Rate +  lo(Expend, span = 0.6) , data = college_trn)
summary(gam3)
plot(gam3)
gam4 <- gam(Outstate ~ Private + PhD +log(Grad.Rate,span = 0.6) +  lo(Expend, span = 0.6) , data = college_trn)
gam4 <- gam(Outstate ~ Private + PhD +lo(Grad.Rate,span = 0.6) +  lo(Expend, span = 0.6) , data = college_trn)
summary(gam4)
plot(gam4)
plot(gam3)
preds <- predict(gam1, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam2, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam4, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam4, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
gam1 <- gam(Outstate ~ Private + PhD +s(Grad.Rate, sp = 0.6) +  s(Expend, sp = 0.6) , data = college_trn)
summary(gam1)
plot(gam1)
gam2 <- gam(Outstate ~ Private + PhD +Grad.Rate +  s(Expend, sp = 0.6) , data = college_trn)
summary(gam2)
plot(gam2)
gam3 <- gam(Outstate ~ Private + PhD +Grad.Rate +  lo(Expend, span = 0.6) , data = college_trn)
summary(gam3)
plot(gam3)
gam4 <- gam(Outstate ~ Private + PhD +lo(Grad.Rate,span = 0.6) +  lo(Expend, span = 0.6) , data = college_trn)
summary(gam4)
plot(gam4)
preds <- predict(gam1, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam2, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam4, newdata = college_tst)
preds <- predict(gam3, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
preds <- predict(gam4, newdata = college_tst)
sqrt(mean((college_tst$Outstate - preds)^2))
setwd("~/GitHubFiles/CPS-Farm-To-Facility-Cilantro/Data_Cilantro_Outputs")
library(tidyverse)
TD<-read_csv("Product_Testing_Data.csv")
View(TD)
TD<-read_csv("Product_Testing_Data.csv",col_names = F)
View(TD)
TD<-read_csv("Product_Testing_Data.csv")
TD<-TD[,2:3]
View(TD)
View(TD)
model<-lm(Result~Cont, data = TD)
model<-lm(Results~Cont, data = TD)
model<-lm(Results~Cont, data = TD)
model<-glm(Results~Cont, data = TD,family = binomial(link = "logit")
model<-glm(Results~Cont, data = TD,family = binomial(link = "logit"))
model
model
summary(model)
library(pscl)
install.packages(:pscl)
install.packages("pscl")
library(pscl)
pR2(model)
install.packages("pROC")
library(pROC)
?hltest
??hltest
library(ResourceSelection)
install.packages("ResourceSelection")
library(ResourceSelection)
hoslem.test(model)
hoslem.test(Results~Cont, data = TD,family = binomial(link = "logit"))
hoslem.test(Results~Cont, G= 10)
hoslem.test(Results~Cont,data = TD, G= 10)
hoslem.test(Results~Cont,data = TD, g= 10)
hoslem.test(TD$Results~TD$Cont, g= 10)
hoslem.test(y=TD$Resultsx=TD$Cont, g= 10)
hoslem.test(y=TD$Results,x=TD$Cont, g= 10)
hoslem.test(TD$Results,model)
hoslem.test(TD$Results,fitted(model))
hoslem.test(model$Result,fitted(model))
hoslem.test(model$Results,fitted(model))
model$Results
model<-glm(Results~Cont, data = TD,family = binomial(link = "logit"))
hoslem.test(model$Results,fitted(model))
model$Results
fitted(model)
hoslem.test(TD$Results,fitted(model), g=10)
install.packages("glmtoolbox")
library(glmtoolbox)
hltest(model)
model<-glm(Results~Cont, data = TD,family = binomial(link = "probit"))
hltest(model)
hltest(model)
model<-glm(Results~Cont, data = TD,family = binomial(link = "logit"))
hltest(model)
fitted(model)
hltest(model)
hoslem.test(model$y, fitted(model), g = 10)
model$y
fitted(model)
model$y
model<-glm(Results~Cont, data = TD,family = binomial(link = "logit"))
hoslem.test(model$y, fitted(model), g = 10)
model
#water testing
TD_W<-read_csv("Water_Testing_Data.csv")
TD_W<-TD[,2:3]
model_W<-glm(Results~Cont, data = TD_W,family = binomial(link = "logit"))
hoslem.test(model_W$y, fitted(model_W), g = 10)
TD<-read_csv("Product_Testing_Data.csv")
TD<-TD[,2:3]
model<-glm(Results~Cont, data = TD,family = binomial(link = "logit"))
hoslem.test(model$y, fitted(model), g = 10)
TD_W<-read_csv("Water_Testing_Data.csv")
TD_W<-TD[,2:3]
model_W<-glm(Results~Cont, data = TD_W,family = binomial(link = "logit"))
hoslem.test(model_W$y, fitted(model_W), g = 10)
model_W<-glm(Results~Cont, data = TD_W,family = binomial(link = "logit"))
model_W
fitted(model_W)
TD_W<-read_csv("Water_Testing_Data.csv")
TD_W<-TD_W[,2:3]
model_W<-glm(Results~Cont, data = TD_W,family = binomial(link = "logit"))
hoslem.test(model_W$y, fitted(model_W), g = 10)
#water testing
TD_W<-read_csv("Water_Testing_Data.csv")
TD_W<-TD_W[,2:3]
model_W<-glm(Results~Cont, data = TD_W,family = binomial(link = "logit"))
model_W
TD_W
View(TD_W)
teengamb
install.packages("faraway")
library(faraway)
colnames(teengamb)
lm(gabmle~sex+status+income+verbal)
model_1<-lm(gamble~sex+status+income+verbal)
model_1<-lm(gamble~sex+status+income+verbal, data = teengamb)
summary (model_1)
model_1$coefficients
model_1$effects
summary (model_1)
model_1$residuals
which_max(model_1$residuals)
which.max(model_1$residuals)
fitted(model_1)
fitted(model_1)[24]
confint(model_1)
Avergae_status =mean(teengamb$status)
Average_status =mean(teengamb$status)
Average_income =mean(teengamb$income)
Average_verbal =mean(teengamb$verbal)
new_df <- data.frame(sex = 1,"status" = Average_status, "income" = Average_income, verbal =Average_verbal )
predict(model_1, new_df)
predict(model_1, new_df, interval = "prediction")
model_income<-lm(gamble~income, data = teengamb)
anova(model_1, model_income)
summary(model_income)
model_hip <- lm(hipcenter~Age+Weight+Ht data, seatpos )
model_hip <- lm(hipcenter~Age+Weight+Ht data= seatpos )
seatpos
model_hip <- lm(hipcenter ~ Age+ Weight + Ht data= seatpos )
hipmod <- lm(hipcenter ~ Age+ Weight + Ht data= seatpos )
hipmod <- lm(hipcenter ~ Age+ Weight + Ht, data= seatpos)
summary(hipmod)
summary(hipmod)
summary(hipmod)
hipmod_shoes <- lm(hipcenter ~ Age+ Weight + Ht +Htshoes, data= seatpos)
seatpos
hipmod_shoes <- lm(hipcenter ~ Age+ Weight + Ht +HtShoes, data= seatpos)
summary(hipmod_shoes)
anova(hipmod, hipmod_shoes)
